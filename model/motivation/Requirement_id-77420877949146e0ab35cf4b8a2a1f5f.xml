<archimate:Requirement
    xmlns:archimate="http://www.archimatetool.com/archimate"
    name="SI-19(6): De-identification | Differential Privacy"
    id="id-77420877949146e0ab35cf4b8a2a1f5f"
    documentation="Prevent disclosure of personally identifiable information by adding non-deterministic noise to the results of mathematical operations before the results are reported.">
  <properties
      key="Control Identifier"
      value="SI-19(6)"/>
  <properties
      key="Latest Sync Date"
      value="19/12/24 09:18:14"/>
  <properties
      key="Discussion"
      value="The mathematical definition for differential privacy holds that the result of a dataset analysis should be approximately the same before and after the addition or removal of a single data record (which is assumed to be the data from a single individual). In its most basic form, differential privacy applies only to online query systems. However, it can also be used to produce machine-learning statistical classifiers and synthetic data. Differential privacy comes at the cost of decreased accuracy of results, forcing organizations to quantify the trade-off between privacy protection and the overall accuracy, usefulness, and utility of the de-identified dataset. Non-deterministic noise can include adding small, random values to the results of mathematical operations in dataset analysis."/>
  <properties
      key="Related Controls"
      value="SC-12, SC-13."/>
</archimate:Requirement>
